{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3f0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aca881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# define the function for reducing memory usage when importing data\n",
    "def reduce_memory_usage(df):\n",
    "  \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e41f4d3",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76916c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countplot_function(df, column, hue=\"TARGET\", figsize=(10, 5), rotation=90):\n",
    "    \"\"\"\n",
    "    Plots a countplot with labeled values on each bar.\n",
    "\n",
    "    Parameters:\n",
    "    - data (DataFrame): The dataset.\n",
    "    - column (str): Categorical column to plot.\n",
    "    - hue (str): Column for grouping (default is \"TARGET\").\n",
    "    - figsize (tuple): Figure size (default is (10, 5)).\n",
    "    - rotation (int): Rotation angle for x-axis labels (default is 90).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)  # Set figure size\n",
    "    ax = sns.countplot(data=data, x=column, hue=hue)\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=rotation)\n",
    "\n",
    "    # Add count labels on top of bars\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{int(p.get_height())}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "    plt.title(f\"Countplot of {column} by {hue}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b9773",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the data that has missing values > 65%\n",
    "def dropna_over50(df):\n",
    "    missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (missing_values / len(df) * 100)\n",
    "\n",
    "    missing_data_over_50 = missing_percent[missing_percent > 50]\n",
    "    print(f'There are: {len(missing_data_over_50)} columns missing data over 50%')\n",
    "    print(missing_data_over_50)\n",
    "\n",
    "#dropping columns that have more than 65% null values\n",
    "    df.drop(columns = missing_data_over_50.index, inplace=True)\n",
    "    print('\\n')\n",
    "    print(f'Shape of the df after removing missing data over 50% : {df.shape}')\n",
    "    \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_cat_cols(df):\n",
    "    \n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "    for col in cat_cols:\n",
    "        df[col] = pd.factorize(df[col])[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ae079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly-correlated numerical variables\n",
    "# Identify pairs of features with correlation above a threshold\n",
    "def redundant_data(df,correlation_matrix):\n",
    "    threshold = 0.8\n",
    "    to_drop = []  # List to store columns to drop\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "    correlation_matrix = df[numeric_columns].corr()\n",
    "    \n",
    "# Looping through the correlation matrix to find highly correlated pairs\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "                colname = correlation_matrix.columns[i]\n",
    "                if colname not in to_drop:\n",
    "                    to_drop.append(colname)\n",
    "\n",
    "# Drop one column from each highly correlated pair\n",
    "    to_drop = list(set(to_drop) & set(df.columns))\n",
    "\n",
    "    # Drop columns\n",
    "    df.drop(columns=to_drop, inplace=True)\n",
    "    print(f\"Dropped {len(to_drop)} redundant columns\")\n",
    "    print(f\"The columns names that were dropped are :{to_drop}\")\n",
    "    print('\\n')\n",
    "    print(f\"Shape of the dataset after removing multicolinearitly: {df.shape}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4be3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputing_na(df):\n",
    "    for col in df.columns:\n",
    "        if not df[col].dtype == 'number':\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    print(\"Imputed all na values\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers_sd(df, threshold=3, exclude_columns=None):\n",
    "    \"\"\"\n",
    "    Caps outliers at Â±3 standard deviations for all numeric columns,\n",
    "    except those in exclude_columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    threshold (float): Standard deviation threshold (default is 3).\n",
    "    exclude_columns (list): List of column names to exclude from capping.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with outliers capped for numeric columns only.\n",
    "    \"\"\"\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = []\n",
    "        \n",
    "    df_capped = df.copy()\n",
    "    # Select only numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for column in numeric_columns:\n",
    "        if column in exclude_columns:\n",
    "            continue  # Skip excluded column\n",
    "        \n",
    "        mean = df[column].mean()\n",
    "        std_dev = df[column].std()\n",
    "\n",
    "        lower_bound = mean - threshold * std_dev\n",
    "        upper_bound = mean + threshold * std_dev\n",
    "\n",
    "        df_capped[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "        df_capped = df\n",
    "    return df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
